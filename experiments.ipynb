{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2425fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from simulation import citygraph_dataset\n",
    "# from learning import inductive_route_learning, eval_route_generator, bee_colony\n",
    "from learning.bee_colony import main as main_bee  # я так обозвал\n",
    "from learning.eval_route_generator import main as main_eval # я так обозвал\n",
    "from omegaconf import OmegaConf, DictConfig\n",
    "from simulation import drawing\n",
    "\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19a75b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 125.15it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = citygraph_dataset.DynamicCityGraphDataset(\n",
    "    min_nodes=25,\n",
    "    max_nodes=25,\n",
    "    edge_keep_prob=0.7,\n",
    "    data_type=citygraph_dataset.MIXED,  # or any other type you want\n",
    "    directed=False,\n",
    "    fully_connected_demand=True,  # default SIDE_LENGTH_M\n",
    "    mumford_style=True,\n",
    "    pos_only=False\n",
    ")\n",
    "\n",
    "# Generate graphs\n",
    "n_graphs = 1000  # number of graphs you want to generate\n",
    "graphs = [dataset.generate_graph(draw=False) for _ in tqdm(range(n_graphs))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7624d7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "# Путь для сохранения\n",
    "save_path = Path('./output_graphs')\n",
    "if not save_path.exists():\n",
    "    save_path.mkdir(parents=True)\n",
    "\n",
    "# Сохраняем объект в файл\n",
    "with open(save_path / 'raw_graphs_1000.pkl', 'wb') as ff:\n",
    "    pickle.dump(graphs, ff)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5dc7ba10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(save_path / 'raw_graphs_1000.pkl', 'rb') as f:\n",
    "    graphs = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a99fa3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hydra import initialize_config_dir, compose\n",
    "from omegaconf import OmegaConf\n",
    "import os\n",
    "\n",
    "cfg_dir = os.path.abspath(\"../TNDP_learning/cfg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1dd387e",
   "metadata": {},
   "source": [
    "### Обучение LC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f734226f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with initialize_config_dir(config_dir=cfg_dir, job_name=\"app\"):\n",
    "    cfg_learn = compose(config_name=\"ppo_20nodes_copy.yaml\", # в этот файл можно положить путь к пикл файлу с графами, также можно попробовать другие параметры на обучение\n",
    "                            overrides=[\"+run_name=random_graphs_weighted_connectivity\"]) # при желании можно накинуть ему имя "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c49cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(OmegaConf.to_yaml(cfg_learn)) # чисто проверка как выглядит конфиг "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7241c10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from learning import inductive_route_learning\n",
    "inductive_route_learning.setup_and_train(cfg_learn) # веса для модели вернутся в папку output, там будет файл .pt / при желании можно накинуть ему имя "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6dab43",
   "metadata": {},
   "source": [
    "### Стартовый набор маршрутов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b7be707",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'mandl'\n",
    "demand_time_weight = 0.33\n",
    "route_time_weight = 0.33\n",
    "median_connectivity_weight = 0.33\n",
    "experiment_name = f'exp_weighted_connectivity_{dataset_name}_pp_{demand_time_weight}_op_{route_time_weight}_cp_{median_connectivity_weight}'\n",
    "initial_routes_name = experiment_name+ '_starting'\n",
    "generated_routes_name = experiment_name + '_generated'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31951701",
   "metadata": {},
   "outputs": [],
   "source": [
    "with initialize_config_dir(config_dir=cfg_dir, version_base=None):\n",
    "    \n",
    "    cfg_eval = compose(\n",
    "        config_name=\"eval_model_mumford\",   # из @hydra.main\n",
    "        overrides=[\n",
    "            f\"+eval={dataset_name}\", # конфиг в котором задается кол-во маршрутов и их макс и мин длины (можно заменить на vo для теста по ваське)\n",
    "            \"+model.weights=../TNDP_learning/output/inductive_random_graphs_weighted_connectivity_checkpoints/iter990.pt\", # путь к весам модели\n",
    "            f\"++run_name={initial_routes_name}\", # имя запуска, вернет pickle файл с тензором в output_routes\n",
    "            f\"++experiment.cost_function.kwargs.demand_time_weight={demand_time_weight}\",\n",
    "            f\"++experiment.cost_function.kwargs.route_time_weight={route_time_weight}\",\n",
    "            f\"++experiment.cost_function.kwargs.median_connectivity_weight={median_connectivity_weight}\"\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d992ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(OmegaConf.to_yaml(cfg_eval)) # чисто проверка как выглядит конфиг "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e28c6de9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/TNDP_learning/learning/utils.py:321: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /pytorch/aten/src/ATen/native/ReduceOps.cpp:1831.)\n",
      "  out_stats = (final_costs.mean(), final_costs.std(), unserved_demand,  metrics)\n"
     ]
    }
   ],
   "source": [
    "metrics, unserved_demand = main_eval(cfg_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5ba987df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cost': tensor([0.5242]),\n",
       " 'ATT': tensor([12.0873]),\n",
       " 'RTT': tensor([164.]),\n",
       " '$d_0$': tensor([69.0430]),\n",
       " '$d_1$': tensor([28.0026]),\n",
       " '$d_2$': tensor([2.9544]),\n",
       " '$d_{un}$': tensor([0.]),\n",
       " '# disconnected node pairs': tensor([0.]),\n",
       " '# stops out of bounds': tensor([0.]),\n",
       " 'median_connectivity': tensor([780.]),\n",
       " 'median_connectivity_weighted': tensor([89.6081]),\n",
       " 'average wall-clock duration': tensor([1.3691]),\n",
       " 'average # iterations': tensor([0.])}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e89b20b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unserved_demand"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a312e6b0",
   "metadata": {},
   "source": [
    "### Генерация "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2be692dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with initialize_config_dir(config_dir=cfg_dir, version_base=None):\n",
    "    cfg_neural = compose(\n",
    "        config_name=\"neural_bco_mumford\",\n",
    "        overrides=[\n",
    "            f\"+eval={dataset_name}\", # конфиг в котором задается кол-во маршрутов и их макс и мин длины (можно заменить на vo для теста по ваське)\n",
    "            \"+model.weights=../TNDP_learning/output/inductive_random_graphs_checkpoints/iter990.pt\", # путь к весам модели\n",
    "            f\"++run_name={generated_routes_name}\", # имя запуска, вернет pickle файл с тензором в output_routes\n",
    "            f\"++experiment.cost_function.kwargs.demand_time_weight={demand_time_weight}\",\n",
    "            f\"++experiment.cost_function.kwargs.route_time_weight={route_time_weight}\",\n",
    "            f\"++experiment.cost_function.kwargs.median_connectivity_weight={median_connectivity_weight}\",\n",
    "            f\"init.path=output_routes/nn_construction_{initial_routes_name}_routes.pkl\",\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eaf38fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(OmegaConf.to_yaml(cfg_neural)) # чисто проверка как выглядит конфиг "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d8410e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics, unserved_demand = main_bee(cfg_neural)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1cfcb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics['median_connectivity'] /= 60 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579f7b4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.954\t244.0\t12.0\t0.332\t0.0\t84.393\t13.166\t2.441\n",
      "10.954\t244.0\t12.0\t0.332\t0.0\t84.393\t13.166\t2.441\n"
     ]
    }
   ],
   "source": [
    "# Порядок нужных ключей\n",
    "keys_order = ['ATT', 'RTT', 'median_connectivity','median_connectivity_weighted', 'cost', '$d_{un}$', '$d_0$', '$d_1$', '$d_2$']\n",
    "\n",
    "print('\\t'.join(str(round(metrics[key].item(),3)) for key in keys_order))\n",
    "print('\\t'.join(str(round(metrics[key].item(),3)) for key in keys_order))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d06294",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running experiments:   0%|          | 0/35 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/TNDP_learning/learning/utils.py:320: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /pytorch/aten/src/ATen/native/ReduceOps.cpp:1831.)\n",
      "  out_stats = (final_costs.mean(), final_costs.std(), metrics)\n",
      "Running experiments:  57%|█████▋    | 20/35 [16:15:46<12:11:49, 2927.32s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 98\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m initialize_config_dir(config_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(cfg_dir), version_base\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     86\u001b[0m     cfg_bee \u001b[38;5;241m=\u001b[39m compose(\n\u001b[1;32m     87\u001b[0m         config_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mneural_bco_mumford\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     88\u001b[0m         overrides\u001b[38;5;241m=\u001b[39m[\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     96\u001b[0m         ]\n\u001b[1;32m     97\u001b[0m     )\n\u001b[0;32m---> 98\u001b[0m bee_metrics \u001b[38;5;241m=\u001b[39m \u001b[43mmain_bee\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg_bee\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     99\u001b[0m bee_metrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmedian_connectivity\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m60\u001b[39m\n\u001b[1;32m    101\u001b[0m keys_order \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mATT\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRTT\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmedian_connectivity\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcost\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m$d_\u001b[39m\u001b[38;5;132;01m{un}\u001b[39;00m\u001b[38;5;124m$\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m$d_0$\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m$d_1$\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m$d_2$\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/TNDP_learning/venv/lib/python3.10/site-packages/hydra/main.py:79\u001b[0m, in \u001b[0;36mmain.<locals>.main_decorator.<locals>.decorated_main\u001b[0;34m(cfg_passthrough)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(task_function)\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorated_main\u001b[39m(cfg_passthrough: Optional[DictConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m cfg_passthrough \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 79\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg_passthrough\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     81\u001b[0m         args_parser \u001b[38;5;241m=\u001b[39m get_args_parser()\n",
      "File \u001b[0;32m~/TNDP_learning/learning/bee_colony.py:536\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(cfg)\u001b[0m\n\u001b[1;32m    533\u001b[0m nt1b \u001b[38;5;241m=\u001b[39m cfg\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_type1_bees\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    534\u001b[0m nt2b \u001b[38;5;241m=\u001b[39m cfg\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_type2_bees\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    535\u001b[0m test_output \u001b[38;5;241m=\u001b[39m \\\n\u001b[0;32m--> 536\u001b[0m     \u001b[43mlrnu\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbee_colony\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_dl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcost_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    537\u001b[0m \u001b[43m        \u001b[49m\u001b[43msum_writer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msum_writer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msilent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_bees\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_bees\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    538\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_iterations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_iterations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_type1_bees\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnt1b\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_type2_bees\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnt2b\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\n\u001b[1;32m    539\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDEVICE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbee_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbee_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_routes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    540\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_linking_unlinked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_linking_unlinked\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    541\u001b[0m routes \u001b[38;5;241m=\u001b[39m test_output[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    542\u001b[0m metrics \u001b[38;5;241m=\u001b[39m test_output[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m]\n",
      "File \u001b[0;32m~/TNDP_learning/venv/lib/python3.10/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/TNDP_learning/learning/utils.py:245\u001b[0m, in \u001b[0;36mtest_method\u001b[0;34m(method_fn, dataloader, eval_cfg, init_cfg, cost_obj, sum_writer, silent, return_routes, device, iter_num, *method_args, **method_kwargs)\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m init_network \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m init_network\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m eval_cfg\u001b[38;5;241m.\u001b[39mn_routes, \\\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minitial solution has wrong number of routes \u001b[39m\u001b[38;5;124m\"\u001b[39m\\\n\u001b[1;32m    242\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00minit_network\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, should be \u001b[39m\u001b[38;5;132;01m{\u001b[39;00meval_cfg\u001b[38;5;241m.\u001b[39mn_routes\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    244\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m method_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 245\u001b[0m     state, cost_history \u001b[38;5;241m=\u001b[39m \u001b[43mmethod_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcost_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msilent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msilent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    246\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43minit_network\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_network\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    247\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43msum_writer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msum_writer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmethod_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    248\u001b[0m \u001b[43m                                    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmethod_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    250\u001b[0m     \u001b[38;5;66;03m# just evaluate the initial solution\u001b[39;00m\n\u001b[1;32m    251\u001b[0m     state\u001b[38;5;241m.\u001b[39madd_new_routes(init_network)\n",
      "File \u001b[0;32m~/TNDP_learning/learning/bee_colony.py:165\u001b[0m, in \u001b[0;36mbee_colony\u001b[0;34m(state, cost_obj, init_network, n_bees, passes_per_it, mod_steps_per_pass, shorten_prob, n_iterations, n_type1_bees, n_type2_bees, silent, force_linking_unlinked, bee_model, sum_writer)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m mi \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(mod_steps_per_pass):\n\u001b[1;32m    145\u001b[0m \n\u001b[1;32m    146\u001b[0m     \u001b[38;5;66;03m# # flatten batch and bee dimensions\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    159\u001b[0m \n\u001b[1;32m    160\u001b[0m     \u001b[38;5;66;03m# unlike the original paper, choose routes uniformly at random\u001b[39;00m\n\u001b[1;32m    161\u001b[0m     chosen_route_idxs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandint(high\u001b[38;5;241m=\u001b[39mn_routes\u001b[38;5;241m.\u001b[39mitem(), \n\u001b[1;32m    162\u001b[0m                                       size\u001b[38;5;241m=\u001b[39m(batch_size, n_bees), \n\u001b[1;32m    163\u001b[0m                                       device\u001b[38;5;241m=\u001b[39mdev)                \n\u001b[1;32m    164\u001b[0m     new_bee_networks \u001b[38;5;241m=\u001b[39m \\\n\u001b[0;32m--> 165\u001b[0m         \u001b[43mget_mutants\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbee_networks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchosen_route_idxs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_type1_bees\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mn_type2_bees\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdirect_sat_dmd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshorten_prob\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mstreet_node_neighbours\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshortest_paths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mforce_linking_unlinked\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbee_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrpc_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mbee_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    171\u001b[0m     new_bee_costs, new_bee_metrics \u001b[38;5;241m=\u001b[39m \\\n\u001b[1;32m    172\u001b[0m         batched_cost_fn(new_bee_networks)\n\u001b[1;32m    174\u001b[0m     better_idxs \u001b[38;5;241m=\u001b[39m new_bee_costs \u001b[38;5;241m<\u001b[39m bee_costs\n",
      "File \u001b[0;32m~/TNDP_learning/learning/bee_colony.py:259\u001b[0m, in \u001b[0;36mget_mutants\u001b[0;34m(bee_networks, chosen_route_idxs, n_type1, n_type2, direct_sat_dmd, shorten_prob, street_node_neighbours, shortest_paths, force_linking_unlinked, bee_model, rpc_model, env_state)\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;66;03m# modify type 1 routes\u001b[39;00m\n\u001b[1;32m    257\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m bee_model \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    258\u001b[0m     \u001b[38;5;66;03m# run it on all bees...\u001b[39;00m\n\u001b[0;32m--> 259\u001b[0m     new_type1_networks \u001b[38;5;241m=\u001b[39m \u001b[43mget_neural_variants\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbee_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    260\u001b[0m \u001b[43m                                             \u001b[49m\u001b[43mbee_networks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    261\u001b[0m \u001b[43m                                             \u001b[49m\u001b[43mchosen_route_idxs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    262\u001b[0m     \u001b[38;5;66;03m# ...and keep only the type 1 bee routes\u001b[39;00m\n\u001b[1;32m    263\u001b[0m     new_type1_routes \u001b[38;5;241m=\u001b[39m new_type1_networks[:, type1_idxs, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m~/TNDP_learning/learning/bee_colony.py:317\u001b[0m, in \u001b[0;36mget_neural_variants\u001b[0;34m(model, env_state, bee_networks, drop_route_idxs, greedy)\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[38;5;66;03m# plan a new route with the model\u001b[39;00m\n\u001b[1;32m    316\u001b[0m env_state\u001b[38;5;241m.\u001b[39mreplace_routes(flatbee_kept_routes)\n\u001b[0;32m--> 317\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgreedy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    318\u001b[0m env_state \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mstate\n\u001b[1;32m    319\u001b[0m routes \u001b[38;5;241m=\u001b[39m tu\u001b[38;5;241m.\u001b[39mget_batch_tensor_from_routes(env_state\u001b[38;5;241m.\u001b[39mroutes, \n\u001b[1;32m    320\u001b[0m                                          bee_networks\u001b[38;5;241m.\u001b[39mdevice)\n",
      "File \u001b[0;32m~/TNDP_learning/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/TNDP_learning/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/TNDP_learning/learning/models.py:1279\u001b[0m, in \u001b[0;36mPathCombiningRouteGenerator.forward\u001b[0;34m(self, state, greedy)\u001b[0m\n\u001b[1;32m   1276\u001b[0m all_entropy \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   1278\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m state\u001b[38;5;241m.\u001b[39mis_done()\u001b[38;5;241m.\u001b[39mall():\n\u001b[0;32m-> 1279\u001b[0m     action, logits, entropy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgreedy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1280\u001b[0m     \u001b[38;5;66;03m# if the action is to add stops, the state must not be done\u001b[39;00m\n\u001b[1;32m   1281\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m state\u001b[38;5;241m.\u001b[39mis_done()[action[:, \u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39many(), \\\n\u001b[1;32m   1282\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-null action when state is done!\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/TNDP_learning/learning/models.py:1360\u001b[0m, in \u001b[0;36mPathCombiningRouteGenerator.step\u001b[0;34m(self, state, greedy, actions, precalc_data)\u001b[0m\n\u001b[1;32m   1356\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstepping\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1358\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m precalc_data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1359\u001b[0m     node_descs, node_pad_mask, np_embeds, path_scores \u001b[38;5;241m=\u001b[39m \\\n\u001b[0;32m-> 1360\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_encode_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1361\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1362\u001b[0m     node_descs, node_pad_mask, np_embeds, path_scores \u001b[38;5;241m=\u001b[39m precalc_data\n",
      "File \u001b[0;32m~/TNDP_learning/learning/models.py:1545\u001b[0m, in \u001b[0;36mPathCombiningRouteGenerator._encode_graph\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m   1543\u001b[0m     node_descs, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackbone_net(input_batch)\n\u001b[1;32m   1544\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1545\u001b[0m     node_descs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackbone_net\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1547\u001b[0m node_descs, node_pad_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfold_node_descs(node_descs, state)\n\u001b[1;32m   1548\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msymmetric_routes:\n\u001b[1;32m   1549\u001b[0m     \u001b[38;5;66;03m# just sum them\u001b[39;00m\n",
      "File \u001b[0;32m~/TNDP_learning/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/TNDP_learning/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/TNDP_learning/learning/models.py:2354\u001b[0m, in \u001b[0;36mGraphNetBase.forward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   2352\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_helper(data)\n\u001b[1;32m   2353\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2354\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2355\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpostprocess(\u001b[38;5;241m*\u001b[39moutput)\n",
      "File \u001b[0;32m~/TNDP_learning/learning/models.py:2378\u001b[0m, in \u001b[0;36mGraphNetBase._forward_helper\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   2374\u001b[0m edge_descs \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39medge_attr\n\u001b[1;32m   2376\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m li, layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers):\n\u001b[1;32m   2377\u001b[0m     \u001b[38;5;66;03m# apply the layer and graph normalization\u001b[39;00m\n\u001b[0;32m-> 2378\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode_descs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_descs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2379\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgives_edge_features:\n\u001b[1;32m   2380\u001b[0m         layer_nodes, layer_edges \u001b[38;5;241m=\u001b[39m out\n",
      "File \u001b[0;32m~/TNDP_learning/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/TNDP_learning/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/TNDP_learning/venv/lib/python3.10/site-packages/torch_geometric/nn/conv/gatv2_conv.py:325\u001b[0m, in \u001b[0;36mGATv2Conv.forward\u001b[0;34m(self, x, edge_index, edge_attr, return_attention_weights)\u001b[0m\n\u001b[1;32m    319\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[1;32m    320\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe usage of \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124medge_attr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madd_self_loops\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msimultaneously is currently not yet supported for \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124medge_index\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m in a \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSparseTensor\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m form\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    324\u001b[0m \u001b[38;5;66;03m# edge_updater_type: (x: PairTensor, edge_attr: OptTensor)\u001b[39;00m\n\u001b[0;32m--> 325\u001b[0m alpha \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_updater\u001b[49m\u001b[43m(\u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx_l\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_r\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    326\u001b[0m \u001b[43m                          \u001b[49m\u001b[43medge_attr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43medge_attr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    328\u001b[0m \u001b[38;5;66;03m# propagate_type: (x: PairTensor, alpha: Tensor)\u001b[39;00m\n\u001b[1;32m    329\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpropagate(edge_index, x\u001b[38;5;241m=\u001b[39m(x_l, x_r), alpha\u001b[38;5;241m=\u001b[39malpha)\n",
      "File \u001b[0;32m/tmp/torch_geometric.nn.conv.gatv2_conv_GATv2Conv_edge_updater_0vx0s0ak.py:176\u001b[0m, in \u001b[0;36medge_updater\u001b[0;34m(self, edge_index, x, edge_attr, size)\u001b[0m\n\u001b[1;32m    166\u001b[0m             kwargs \u001b[38;5;241m=\u001b[39m CollectArgs(\n\u001b[1;32m    167\u001b[0m                 x_j\u001b[38;5;241m=\u001b[39mhook_kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx_j\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    168\u001b[0m                 x_i\u001b[38;5;241m=\u001b[39mhook_kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx_i\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    172\u001b[0m                 dim_size\u001b[38;5;241m=\u001b[39mhook_kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdim_size\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    173\u001b[0m             )\n\u001b[1;32m    174\u001b[0m \u001b[38;5;66;03m# End Edge Update Forward Pre Hook #########################################\u001b[39;00m\n\u001b[0;32m--> 176\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_update\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx_j\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx_j\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx_i\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx_i\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m    \u001b[49m\u001b[43medge_attr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_attr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m    \u001b[49m\u001b[43mptr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mptr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdim_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdim_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;66;03m# Begin Edge Update Forward Hook ###########################################\u001b[39;00m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mis_scripting() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_compiling():\n",
      "File \u001b[0;32m~/TNDP_learning/venv/lib/python3.10/site-packages/torch_geometric/nn/conv/gatv2_conv.py:364\u001b[0m, in \u001b[0;36mGATv2Conv.edge_update\u001b[0;34m(self, x_j, x_i, edge_attr, index, ptr, dim_size)\u001b[0m\n\u001b[1;32m    362\u001b[0m     edge_attr \u001b[38;5;241m=\u001b[39m edge_attr\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    363\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlin_edge \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 364\u001b[0m edge_attr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlin_edge\u001b[49m\u001b[43m(\u001b[49m\u001b[43medge_attr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    365\u001b[0m edge_attr \u001b[38;5;241m=\u001b[39m edge_attr\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheads, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout_channels)\n\u001b[1;32m    366\u001b[0m x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m edge_attr\n",
      "File \u001b[0;32m~/TNDP_learning/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/TNDP_learning/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/TNDP_learning/venv/lib/python3.10/site-packages/torch_geometric/nn/dense/linear.py:147\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m    142\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Forward pass.\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \n\u001b[1;32m    144\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;124;03m        x (torch.Tensor): The input features.\u001b[39;00m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 147\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from pathlib import Path\n",
    "from hydra import initialize_config_dir, compose\n",
    "from omegaconf import OmegaConf\n",
    "from learning.eval_route_generator import main as main_eval\n",
    "from learning.bee_colony import main as main_bee\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Путь к конфигам\n",
    "cfg_dir = Path(\"../TNDP_learning/cfg\").resolve()\n",
    "\n",
    "# Все параметры экспериментов\n",
    "experiments = [\n",
    "    (\"mandl\", 1, 0, 0),\n",
    "    (\"mandl\", 0, 1, 0),\n",
    "    (\"mandl\", 0, 0, 1),\n",
    "    (\"mandl\", 0.5, 0.5, 0),\n",
    "    (\"mandl\", 0.5, 0, 0.5),\n",
    "    (\"mandl\", 0, 0.5, 0.5),\n",
    "    (\"mandl\", 0.33, 0.33, 0.33),\n",
    "    (\"mumford0\", 1, 0, 0),\n",
    "    (\"mumford0\", 0, 1, 0),\n",
    "    (\"mumford0\", 0, 0, 1),\n",
    "    (\"mumford0\", 0.5, 0.5, 0),\n",
    "    (\"mumford0\", 0.5, 0, 0.5),\n",
    "    (\"mumford0\", 0, 0.5, 0.5),\n",
    "    (\"mumford0\", 0.33, 0.33, 0.33),\n",
    "    (\"mumford1\", 1, 0, 0),\n",
    "    (\"mumford1\", 0, 1, 0),\n",
    "    (\"mumford1\", 0, 0, 1),\n",
    "    (\"mumford1\", 0.5, 0.5, 0),\n",
    "    (\"mumford1\", 0.5, 0, 0.5),\n",
    "    (\"mumford1\", 0, 0.5, 0.5),\n",
    "    (\"mumford1\", 0.33, 0.33, 0.33),\n",
    "    (\"mumford2\", 1, 0, 0),\n",
    "    (\"mumford2\", 0, 1, 0),\n",
    "    (\"mumford2\", 0, 0, 1),\n",
    "    (\"mumford2\", 0.5, 0.5, 0),\n",
    "    (\"mumford2\", 0.5, 0, 0.5),\n",
    "    (\"mumford2\", 0, 0.5, 0.5),\n",
    "    (\"mumford2\", 0.33, 0.33, 0.33),\n",
    "    (\"mumford3\", 1, 0, 0),\n",
    "    (\"mumford3\", 0, 1, 0),\n",
    "    (\"mumford3\", 0, 0, 1),\n",
    "    (\"mumford3\", 0.5, 0.5, 0),\n",
    "    (\"mumford3\", 0.5, 0, 0.5),\n",
    "    (\"mumford3\", 0, 0.5, 0.5),\n",
    "    (\"mumford3\", 0.33, 0.33, 0.33),\n",
    "]\n",
    "\n",
    "# Путь к весам модели\n",
    "model_weights_path = \"../TNDP_learning/output/inductive_random_graphs_weighted_connectivity_checkpoints/iter990.pt\"\n",
    "\n",
    "# CSV файл для результатов\n",
    "results_file = Path(\"experiment_results.csv\")\n",
    "if not results_file.exists():\n",
    "    with open(results_file, mode='w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\n",
    "            \"dataset\", \"demand_time\", \"route_time\", \"connectivity\",\n",
    "            \"ATT\", \"RTT\", \"median_connectivity\",\"median_connectivity_weighted\", \"cost\", \"$d_{un}$\", \"$d_0$\", \"$d_1$\", \"$d_2$\"\n",
    "        ])\n",
    "\n",
    "# Запуск экспериментов с tqdm\n",
    "for dataset_name, dt, rt, ct in tqdm(experiments, desc=\"Running experiments\"):\n",
    "    try:\n",
    "        experiment_name = f\"exp_weighted_connectivity_{dataset_name}_pp_{dt}_op_{rt}_cp_{ct}\"\n",
    "        initial_routes_name = experiment_name + '_starting'\n",
    "        generated_routes_name = experiment_name + '_generated'\n",
    "\n",
    "        with initialize_config_dir(config_dir=str(cfg_dir), version_base=None):\n",
    "            cfg_eval = compose(\n",
    "                config_name=\"eval_model_mumford\",\n",
    "                overrides=[\n",
    "                    f\"+eval={dataset_name.lower()}\",\n",
    "                    f\"+model.weights={model_weights_path}\",\n",
    "                    f\"++run_name={initial_routes_name}\",\n",
    "                    f\"++experiment.cost_function.kwargs.demand_time_weight={dt}\",\n",
    "                    f\"++experiment.cost_function.kwargs.route_time_weight={rt}\",\n",
    "                    f\"++experiment.cost_function.kwargs.median_connectivity_weight={ct}\"\n",
    "                ]\n",
    "            )\n",
    "        eval_metrics, unserved_demand = main_eval(cfg_eval)\n",
    "\n",
    "        with initialize_config_dir(config_dir=str(cfg_dir), version_base=None):\n",
    "            cfg_bee = compose(\n",
    "                config_name=\"neural_bco_mumford\",\n",
    "                overrides=[\n",
    "                    f\"+eval={dataset_name.lower()}\",\n",
    "                    f\"+model.weights={model_weights_path}\",\n",
    "                    f\"++run_name={generated_routes_name}\",\n",
    "                    f\"++experiment.cost_function.kwargs.demand_time_weight={dt}\",\n",
    "                    f\"++experiment.cost_function.kwargs.route_time_weight={rt}\",\n",
    "                    f\"++experiment.cost_function.kwargs.median_connectivity_weight={ct}\",\n",
    "                    f\"init.path=output_routes/nn_construction_{initial_routes_name}_routes.pkl\",\n",
    "                ]\n",
    "            )\n",
    "        bee_metrics, unserved_demand = main_bee(cfg_bee)\n",
    "        bee_metrics['median_connectivity'] /= 60\n",
    "\n",
    "        keys_order = ['ATT', 'RTT', 'median_connectivity', \"median_connectivity_weighted\", 'cost', '$d_{un}$', '$d_0$', '$d_1$', '$d_2$']\n",
    "        row = [dataset_name.lower(), dt, rt, ct] + [round(bee_metrics[k].item(), 4) for k in keys_order]\n",
    "\n",
    "        with open(results_file, mode='a', newline='') as f:\n",
    "            csv.writer(f).writerow(row)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[✗] Failed {experiment_name}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401d55cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating mandl:   0%|          | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "/root/TNDP_learning/learning/utils.py:320: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /pytorch/aten/src/ATen/native/ReduceOps.cpp:1831.)\n",
      "  out_stats = (final_costs.mean(), final_costs.std(), metrics)\n",
      "Evaluating mandl:  14%|█▍        | 1/7 [00:01<00:11,  1.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ",6.000,0.332,10.954,244.000,84.393,13.166,2.441,0.000,0.000,0.000,720.000,1.621,0.000\n",
      "{'cost': tensor([0.3319]), 'ATT': tensor([10.9538]), 'RTT': tensor([244.]), '$d_0$': tensor([84.3931]), '$d_1$': tensor([13.1663]), '$d_2$': tensor([2.4406]), '$d_{un}$': tensor([0.]), '# disconnected node pairs': tensor([0.]), '# stops out of bounds': tensor([0.]), 'median_connectivity': tensor([720.]), 'average wall-clock duration': tensor([1.6207]), 'average # iterations': tensor([0.])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, -1.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ",6.000,0.747,13.493,148.000,59.216,36.609,4.110,0.064,0.000,0.000,868.000,-0.701,0.000\n",
      "{'cost': tensor([0.7475]), 'ATT': tensor([13.4926]), 'RTT': tensor([148.]), '$d_0$': tensor([59.2164]), '$d_1$': tensor([36.6089]), '$d_2$': tensor([4.1105]), '$d_{un}$': tensor([0.0642]), '# disconnected node pairs': tensor([0.]), '# stops out of bounds': tensor([0.]), 'median_connectivity': tensor([868.]), 'average wall-clock duration': tensor([-0.7006]), 'average # iterations': tensor([0.])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.60s/it]\n",
      "Evaluating mandl:  43%|████▎     | 3/7 [00:02<00:03,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ",6.000,0.362,11.101,240.000,79.833,19.075,1.092,0.000,0.000,0.000,716.000,1.597,0.000\n",
      "{'cost': tensor([0.3616]), 'ATT': tensor([11.1015]), 'RTT': tensor([240.]), '$d_0$': tensor([79.8330]), '$d_1$': tensor([19.0751]), '$d_2$': tensor([1.0918]), '$d_{un}$': tensor([0.]), '# disconnected node pairs': tensor([0.]), '# stops out of bounds': tensor([0.]), 'median_connectivity': tensor([716.]), 'average wall-clock duration': tensor([1.5975]), 'average # iterations': tensor([0.])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.61s/it]\n",
      "Evaluating mandl:  57%|█████▋    | 4/7 [00:04<00:03,  1.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ",6.000,0.585,13.248,152.000,59.409,39.435,1.156,0.000,0.000,0.000,816.000,1.600,0.000\n",
      "{'cost': tensor([0.5846]), 'ATT': tensor([13.2479]), 'RTT': tensor([152.]), '$d_0$': tensor([59.4091]), '$d_1$': tensor([39.4348]), '$d_2$': tensor([1.1561]), '$d_{un}$': tensor([0.]), '# disconnected node pairs': tensor([0.]), '# stops out of bounds': tensor([0.]), 'median_connectivity': tensor([816.]), 'average wall-clock duration': tensor([1.6001]), 'average # iterations': tensor([0.])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.61s/it]\n",
      "Evaluating mandl:  71%|███████▏  | 5/7 [00:06<00:02,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ",6.000,0.348,10.954,244.000,84.393,13.166,2.441,0.000,0.000,0.000,720.000,1.601,0.000\n",
      "{'cost': tensor([0.3478]), 'ATT': tensor([10.9538]), 'RTT': tensor([244.]), '$d_0$': tensor([84.3931]), '$d_1$': tensor([13.1663]), '$d_2$': tensor([2.4406]), '$d_{un}$': tensor([0.]), '# disconnected node pairs': tensor([0.]), '# stops out of bounds': tensor([0.]), 'median_connectivity': tensor([720.]), 'average wall-clock duration': tensor([1.6012]), 'average # iterations': tensor([0.])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.60s/it]\n",
      "Evaluating mandl:  86%|████████▌ | 6/7 [00:08<00:01,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ",6.000,0.590,13.248,152.000,59.409,39.435,1.156,0.000,0.000,0.000,816.000,1.597,0.000\n",
      "{'cost': tensor([0.5899]), 'ATT': tensor([13.2479]), 'RTT': tensor([152.]), '$d_0$': tensor([59.4091]), '$d_1$': tensor([39.4348]), '$d_2$': tensor([1.1561]), '$d_{un}$': tensor([0.]), '# disconnected node pairs': tensor([0.]), '# stops out of bounds': tensor([0.]), 'median_connectivity': tensor([816.]), 'average wall-clock duration': tensor([1.5967]), 'average # iterations': tensor([0.])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Evaluating mandl: 100%|██████████| 7/7 [00:09<00:00,  1.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ",6.000,0.524,12.087,164.000,69.043,28.003,2.954,0.000,0.000,0.000,780.000,1.620,0.000\n",
      "{'cost': tensor([0.5242]), 'ATT': tensor([12.0873]), 'RTT': tensor([164.]), '$d_0$': tensor([69.0430]), '$d_1$': tensor([28.0026]), '$d_2$': tensor([2.9544]), '$d_{un}$': tensor([0.]), '# disconnected node pairs': tensor([0.]), '# stops out of bounds': tensor([0.]), 'median_connectivity': tensor([780.]), 'average wall-clock duration': tensor([1.6195]), 'average # iterations': tensor([0.])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Эксперименты только с mandl\n",
    "import csv\n",
    "from pathlib import Path\n",
    "from hydra import initialize_config_dir, compose\n",
    "from learning.eval_route_generator import main as main_eval\n",
    "from tqdm import tqdm\n",
    "\n",
    "model_weights_path = \"../TNDP_learning/output/inductive_random_graphs_weighted_connectivity_checkpoints/iter990.pt\"\n",
    "\n",
    "mandl_experiments = [\n",
    "    (\"mandl\", 1, 0, 0),\n",
    "    (\"mandl\", 0, 1, 0),\n",
    "    (\"mandl\", 0, 0, 1),\n",
    "    (\"mandl\", 0.5, 0.5, 0),\n",
    "    (\"mandl\", 0.5, 0, 0.5),\n",
    "    (\"mandl\", 0, 0.5, 0.5),\n",
    "    (\"mandl\", 0.33, 0.33, 0.33),\n",
    "]\n",
    "\n",
    "# CSV файл\n",
    "results_file = Path(\"eval_only_mandl.csv\")\n",
    "if not results_file.exists():\n",
    "    with open(results_file, mode='w', newline='') as f:\n",
    "        csv.writer(f).writerow([\n",
    "            \"dataset\", \"demand_time\", \"route_time\", \"connectivity\",\n",
    "            \"ATT\", \"RTT\", \"median_connectivity\", \"median_connectivity_weighted\", \"cost\", \"$d_{un}$\", \"$d_0$\", \"$d_1$\", \"$d_2$\"\n",
    "        ])\n",
    "\n",
    "# Запуск экспериментов только main_eval\n",
    "for dataset_name, dt, rt, ct in tqdm(mandl_experiments, desc=\"Evaluating mandl\"):\n",
    "    try:\n",
    "        run_name = f\"mandl_weighted_connectivity_eval_pp_{dt}_op_{rt}_cp_{ct}\"\n",
    "\n",
    "        with initialize_config_dir(config_dir=str(cfg_dir), version_base=None):\n",
    "            cfg_eval = compose(\n",
    "                config_name=\"eval_model_mumford\",\n",
    "                overrides=[\n",
    "                    f\"+eval={dataset_name}\",\n",
    "                    f\"+model.weights={model_weights_path}\",\n",
    "                    f\"++run_name={run_name}\",\n",
    "                    f\"++experiment.cost_function.kwargs.demand_time_weight={dt}\",\n",
    "                    f\"++experiment.cost_function.kwargs.route_time_weight={rt}\",\n",
    "                    f\"++experiment.cost_function.kwargs.median_connectivity_weight={ct}\",\n",
    "                ]\n",
    "            )\n",
    "\n",
    "        metrics = main_eval(cfg_eval)\n",
    "        keys_order = ['ATT', 'RTT', 'median_connectivity', \"median_connectivity_weighted\", 'cost', '$d_{un}$', '$d_0$', '$d_1$', '$d_2$']\n",
    "        row = [dataset_name, dt, rt, ct] + [round(metrics[k].item(), 4) for k in keys_order]\n",
    "\n",
    "        with open(results_file, mode='a', newline='') as f:\n",
    "            csv.writer(f).writerow(row)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[✗] Failed eval for {run_name}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1236a1cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
