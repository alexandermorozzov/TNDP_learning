{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2425fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from simulation import citygraph_dataset\n",
    "# from learning import inductive_route_learning, eval_route_generator, bee_colony\n",
    "from learning.bee_colony import main as main_bee  # я так обозвал\n",
    "from learning.eval_route_generator import main as main_eval # я так обозвал\n",
    "from omegaconf import OmegaConf, DictConfig\n",
    "from simulation import drawing\n",
    "\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f19a75b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:07<00:00, 142.41it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = citygraph_dataset.DynamicCityGraphDataset(\n",
    "    min_nodes=25,\n",
    "    max_nodes=25,\n",
    "    edge_keep_prob=0.7,\n",
    "    data_type=citygraph_dataset.MIXED,  # or any other type you want\n",
    "    directed=False,\n",
    "    fully_connected_demand=True,  # default SIDE_LENGTH_M\n",
    "    mumford_style=True,\n",
    "    pos_only=False\n",
    ")\n",
    "\n",
    "# Generate graphs\n",
    "n_graphs = 1000  # number of graphs you want to generate\n",
    "graphs = [dataset.generate_graph(draw=False) for _ in tqdm(range(n_graphs))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7624d7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "# Путь для сохранения\n",
    "save_path = Path('./output_graphs')\n",
    "if not save_path.exists():\n",
    "    save_path.mkdir(parents=True)\n",
    "\n",
    "# Сохраняем объект в файл\n",
    "with open(save_path / 'raw_graphs_1000.pkl', 'wb') as ff:\n",
    "    pickle.dump(graphs, ff)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5dc7ba10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(save_path / 'raw_graphs_1000.pkl', 'rb') as f:\n",
    "    graphs = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a99fa3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hydra import initialize_config_dir, compose\n",
    "from omegaconf import OmegaConf\n",
    "import os\n",
    "\n",
    "cfg_dir = os.path.abspath(\"../TNDP_learning/cfg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1dd387e",
   "metadata": {},
   "source": [
    "### Обучение LC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f734226f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_147434/2784490261.py:1: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  with initialize_config_dir(config_dir=cfg_dir, job_name=\"app\"):\n"
     ]
    }
   ],
   "source": [
    "with initialize_config_dir(config_dir=cfg_dir, job_name=\"app\"):\n",
    "    cfg_learn = compose(config_name=\"ppo_20nodes_copy.yaml\", # в этот файл можно положить путь к пикл файлу с графами, также можно попробовать другие параметры на обучение\n",
    "                            overrides=[\"+run_name=random_graphs\"]) # при желании можно накинуть ему имя \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c49cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(OmegaConf.to_yaml(cfg_learn)) # чисто проверка как выглядит конфиг "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7241c10f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [3:59:55<00:00, 14.40s/it] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.6092)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from learning import inductive_route_learning\n",
    "inductive_route_learning.setup_and_train(cfg_learn) # веса для модели вернутся в папку output, там будет файл .pt / при желании можно накинуть ему имя "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6dab43",
   "metadata": {},
   "source": [
    "### Стартовый набор маршрутов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b7be707",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'mandl'\n",
    "demand_time_weight = 1\n",
    "route_time_weight = 0\n",
    "median_connectivity_weight = 0\n",
    "experiment_name = f'exp_{dataset_name}_pp_{demand_time_weight}_op_{route_time_weight}_cp_{median_connectivity_weight}'\n",
    "initial_routes_name = experiment_name+ '_starting'\n",
    "generated_routes_name = experiment_name + '_generated'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31951701",
   "metadata": {},
   "outputs": [],
   "source": [
    "with initialize_config_dir(config_dir=cfg_dir, version_base=None):\n",
    "    \n",
    "    cfg_eval = compose(\n",
    "        config_name=\"eval_model_mumford\",   # из @hydra.main\n",
    "        overrides=[\n",
    "            f\"+eval={dataset_name}\", # конфиг в котором задается кол-во маршрутов и их макс и мин длины (можно заменить на vo для теста по ваське)\n",
    "            \"+model.weights=../TNDP_learning/output/inductive_random_graphs_checkpoints/iter990.pt\", # путь к весам модели\n",
    "            f\"++run_name={initial_routes_name}\", # имя запуска, вернет pickle файл с тензором в output_routes\n",
    "            f\"++experiment.cost_function.kwargs.demand_time_weight={demand_time_weight}\",\n",
    "            f\"++experiment.cost_function.kwargs.route_time_weight={route_time_weight}\",\n",
    "            f\"++experiment.cost_function.kwargs.median_connectivity_weight={median_connectivity_weight}\"\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d992ced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "experiment:\n",
      "  logdir: null\n",
      "  anomaly: false\n",
      "  cpu: false\n",
      "  seed: 0\n",
      "  symmetric_routes: true\n",
      "  cost_function:\n",
      "    type: mine\n",
      "    kwargs:\n",
      "      mean_stop_time_s: 0\n",
      "      avg_transfer_wait_time_s: 300\n",
      "      demand_time_weight: 1\n",
      "      route_time_weight: 0\n",
      "      median_connectivity_weight: 0\n",
      "      constraint_violation_weight: 5.0\n",
      "      variable_weights: true\n",
      "      pp_fraction: 0.15\n",
      "      op_fraction: 0.15\n",
      "      mcw_fraction: 0.15\n",
      "model:\n",
      "  common:\n",
      "    dropout: 0.0\n",
      "    nonlin_type: ReLU\n",
      "    embed_dim: 64\n",
      "  route_generator:\n",
      "    kwargs:\n",
      "      force_linking_unlinked: false\n",
      "      logit_clip: null\n",
      "      n_nodepair_layers: 3\n",
      "      n_pathscorer_layers: 3\n",
      "      pathscorer_hidden_dim: 16\n",
      "      n_halt_layers: 3\n",
      "      halt_scorer_type: endpoints\n",
      "      serial_halting: true\n",
      "    type: PathCombiningRouteGenerator\n",
      "  backbone_gn:\n",
      "    net_type: graph attn\n",
      "    kwargs:\n",
      "      n_layers: 5\n",
      "      in_node_dim: 4\n",
      "      in_edge_dim: 14\n",
      "      use_norm: false\n",
      "      n_heads: 4\n",
      "      dense: false\n",
      "  weights: ../TNDP_learning/output/inductive_random_graphs_checkpoints/iter990.pt\n",
      "n_samples: 100\n",
      "batch_size: 256\n",
      "eval:\n",
      "  csv: true\n",
      "  n_routes: 6\n",
      "  min_route_len: 2\n",
      "  max_route_len: 8\n",
      "  dataset:\n",
      "    type: mumford\n",
      "    path: ../TNDP_learning/CEC2013Supp/Instances\n",
      "    city: Mandl\n",
      "run_name: exp_mandl_pp_1_op_0_cp_0_starting\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(OmegaConf.to_yaml(cfg_eval)) # чисто проверка как выглядит конфиг "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e28c6de9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ",6.000,0.332,10.954,244.000,84.393,13.166,2.441,0.000,0.000,0.000,720.000,1.629,0.000\n",
      "{'cost': tensor([0.3319]), 'ATT': tensor([10.9538]), 'RTT': tensor([244.]), '$d_0$': tensor([84.3931]), '$d_1$': tensor([13.1663]), '$d_2$': tensor([2.4406]), '$d_{un}$': tensor([0.]), '# disconnected node pairs': tensor([0.]), '# stops out of bounds': tensor([0.]), 'median_connectivity': tensor([720.]), 'average wall-clock duration': tensor([1.6289]), 'average # iterations': tensor([0.])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/root/TNDP_learning/learning/utils.py:320: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /pytorch/aten/src/ATen/native/ReduceOps.cpp:1831.)\n",
      "  out_stats = (final_costs.mean(), final_costs.std(), metrics)\n"
     ]
    }
   ],
   "source": [
    "metrics = main_eval(cfg_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a312e6b0",
   "metadata": {},
   "source": [
    "### Генерация "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2be692dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with initialize_config_dir(config_dir=cfg_dir, version_base=None):\n",
    "    cfg_neural = compose(\n",
    "        config_name=\"neural_bco_mumford\",\n",
    "        overrides=[\n",
    "            f\"+eval={dataset_name}\", # конфиг в котором задается кол-во маршрутов и их макс и мин длины (можно заменить на vo для теста по ваське)\n",
    "            \"+model.weights=../TNDP_learning/output/inductive_random_graphs_checkpoints/iter990.pt\", # путь к весам модели\n",
    "            f\"++run_name={generated_routes_name}\", # имя запуска, вернет pickle файл с тензором в output_routes\n",
    "            f\"++experiment.cost_function.kwargs.demand_time_weight={demand_time_weight}\",\n",
    "            f\"++experiment.cost_function.kwargs.route_time_weight={route_time_weight}\",\n",
    "            f\"++experiment.cost_function.kwargs.median_connectivity_weight={median_connectivity_weight}\",\n",
    "            f\"init.path=output_routes/nn_construction_{initial_routes_name}_routes.pkl\",\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eaf38fbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_bees: 10\n",
      "n_iterations: 400\n",
      "batch_size: 10\n",
      "neural_bees: true\n",
      "force_linking_unlinked: false\n",
      "experiment:\n",
      "  logdir: training_logs\n",
      "  anomaly: false\n",
      "  cpu: false\n",
      "  seed: 0\n",
      "  symmetric_routes: true\n",
      "  cost_function:\n",
      "    type: mine\n",
      "    kwargs:\n",
      "      mean_stop_time_s: 0\n",
      "      avg_transfer_wait_time_s: 300\n",
      "      demand_time_weight: 1\n",
      "      route_time_weight: 0\n",
      "      median_connectivity_weight: 0\n",
      "      constraint_violation_weight: 5.0\n",
      "      variable_weights: true\n",
      "      pp_fraction: 0.15\n",
      "      op_fraction: 0.15\n",
      "      mcw_fraction: 0.15\n",
      "model:\n",
      "  common:\n",
      "    dropout: 0.0\n",
      "    nonlin_type: ReLU\n",
      "    embed_dim: 64\n",
      "  route_generator:\n",
      "    kwargs:\n",
      "      force_linking_unlinked: false\n",
      "      logit_clip: null\n",
      "      n_nodepair_layers: 3\n",
      "      n_pathscorer_layers: 3\n",
      "      pathscorer_hidden_dim: 16\n",
      "      n_halt_layers: 3\n",
      "      halt_scorer_type: endpoints\n",
      "      serial_halting: true\n",
      "    type: PathCombiningRouteGenerator\n",
      "  backbone_gn:\n",
      "    net_type: graph attn\n",
      "    kwargs:\n",
      "      n_layers: 5\n",
      "      in_node_dim: 4\n",
      "      in_edge_dim: 14\n",
      "      use_norm: false\n",
      "      n_heads: 4\n",
      "      dense: false\n",
      "  weights: ../TNDP_learning/output/inductive_random_graphs_checkpoints/iter990.pt\n",
      "init:\n",
      "  method: load\n",
      "  path: output_routes/nn_construction_exp_mandl_pp_1_op_0_cp_0_starting_routes.pkl\n",
      "eval:\n",
      "  csv: true\n",
      "  n_routes: 6\n",
      "  min_route_len: 2\n",
      "  max_route_len: 8\n",
      "  dataset:\n",
      "    type: mumford\n",
      "    path: ../TNDP_learning/CEC2013Supp/Instances\n",
      "    city: Mandl\n",
      "run_name: exp_mandl_pp_1_op_0_cp_0_generated\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(OmegaConf.to_yaml(cfg_neural)) # чисто проверка как выглядит конфиг "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8410e17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [04:15<00:00,  1.57it/s]\n",
      "100%|██████████| 1/1 [04:15<00:00, 255.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ",6.000,0.315,10.390,368.000,93.449,6.230,0.321,0.000,0.000,0.000,716.000,255.154,401.000\n",
      "{'cost': tensor([0.3148]), 'ATT': tensor([10.3899]), 'RTT': tensor([368.]), '$d_0$': tensor([93.4489]), '$d_1$': tensor([6.2299]), '$d_2$': tensor([0.3211]), '$d_{un}$': tensor([0.]), '# disconnected node pairs': tensor([0.]), '# stops out of bounds': tensor([0.]), 'median_connectivity': tensor([716.]), 'average wall-clock duration': tensor([255.1538]), 'average # iterations': tensor([401.])}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "metrics = main_bee(cfg_neural)\n",
    "metrics['median_connectivity'] /= 60 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "579f7b4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.954\t244.0\t12.0\t0.332\t0.0\t84.393\t13.166\t2.441\n",
      "10.954\t244.0\t12.0\t0.332\t0.0\t84.393\t13.166\t2.441\n"
     ]
    }
   ],
   "source": [
    "# Порядок нужных ключей\n",
    "keys_order = ['ATT', 'RTT', 'median_connectivity', 'cost', '$d_{un}$', '$d_0$', '$d_1$', '$d_2$']\n",
    "\n",
    "print('\\t'.join(str(round(metrics[key].item(),3)) for key in keys_order))\n",
    "print('\\t'.join(str(round(metrics[key].item(),3)) for key in keys_order))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d06294",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running experiments:   0%|          | 0/35 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/TNDP_learning/learning/utils.py:320: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /pytorch/aten/src/ATen/native/ReduceOps.cpp:1831.)\n",
      "  out_stats = (final_costs.mean(), final_costs.std(), metrics)\n",
      "Running experiments:  57%|█████▋    | 20/35 [13:20:03<26:28:41, 6354.75s/it]"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from pathlib import Path\n",
    "from hydra import initialize_config_dir, compose\n",
    "from omegaconf import OmegaConf\n",
    "from learning.eval_route_generator import main as main_eval\n",
    "from learning.bee_colony import main as main_bee\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Путь к конфигам\n",
    "cfg_dir = Path(\"../TNDP_learning/cfg\").resolve()\n",
    "\n",
    "# Все параметры экспериментов\n",
    "experiments = [\n",
    "    (\"mandl\", 1, 0, 0),\n",
    "    (\"mandl\", 0, 1, 0),\n",
    "    (\"mandl\", 0, 0, 1),\n",
    "    (\"mandl\", 0.5, 0.5, 0),\n",
    "    (\"mandl\", 0.5, 0, 0.5),\n",
    "    (\"mandl\", 0, 0.5, 0.5),\n",
    "    (\"mandl\", 0.33, 0.33, 0.33),\n",
    "    (\"mumford0\", 1, 0, 0),\n",
    "    (\"mumford0\", 0, 1, 0),\n",
    "    (\"mumford0\", 0, 0, 1),\n",
    "    (\"mumford0\", 0.5, 0.5, 0),\n",
    "    (\"mumford0\", 0.5, 0, 0.5),\n",
    "    (\"mumford0\", 0, 0.5, 0.5),\n",
    "    (\"mumford0\", 0.33, 0.33, 0.33),\n",
    "    (\"mumford1\", 1, 0, 0),\n",
    "    (\"mumford1\", 0, 1, 0),\n",
    "    (\"mumford1\", 0, 0, 1),\n",
    "    (\"mumford1\", 0.5, 0.5, 0),\n",
    "    (\"mumford1\", 0.5, 0, 0.5),\n",
    "    (\"mumford1\", 0, 0.5, 0.5),\n",
    "    (\"mumford1\", 0.33, 0.33, 0.33),\n",
    "    (\"mumford2\", 1, 0, 0),\n",
    "    (\"mumford2\", 0, 1, 0),\n",
    "    (\"mumford2\", 0, 0, 1),\n",
    "    (\"mumford2\", 0.5, 0.5, 0),\n",
    "    (\"mumford2\", 0.5, 0, 0.5),\n",
    "    (\"mumford2\", 0, 0.5, 0.5),\n",
    "    (\"mumford2\", 0.33, 0.33, 0.33),\n",
    "    (\"mumford3\", 1, 0, 0),\n",
    "    (\"mumford3\", 0, 1, 0),\n",
    "    (\"mumford3\", 0, 0, 1),\n",
    "    (\"mumford3\", 0.5, 0.5, 0),\n",
    "    (\"mumford3\", 0.5, 0, 0.5),\n",
    "    (\"mumford3\", 0, 0.5, 0.5),\n",
    "    (\"mumford3\", 0.33, 0.33, 0.33),\n",
    "]\n",
    "\n",
    "# Путь к весам модели\n",
    "model_weights_path = \"../TNDP_learning/output/inductive_random_graphs_checkpoints/iter990.pt\"\n",
    "\n",
    "# CSV файл для результатов\n",
    "results_file = Path(\"experiment_results.csv\")\n",
    "if not results_file.exists():\n",
    "    with open(results_file, mode='w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\n",
    "            \"dataset\", \"demand_time\", \"route_time\", \"connectivity\",\n",
    "            \"ATT\", \"RTT\", \"median_connectivity\", \"cost\", \"$d_{un}$\", \"$d_0$\", \"$d_1$\", \"$d_2$\"\n",
    "        ])\n",
    "\n",
    "# Запуск экспериментов с tqdm\n",
    "for dataset_name, dt, rt, ct in tqdm(experiments, desc=\"Running experiments\"):\n",
    "    try:\n",
    "        experiment_name = f\"exp_{dataset_name}_pp_{dt}_op_{rt}_cp_{ct}\"\n",
    "        initial_routes_name = experiment_name + '_starting'\n",
    "        generated_routes_name = experiment_name + '_generated'\n",
    "\n",
    "        with initialize_config_dir(config_dir=str(cfg_dir), version_base=None):\n",
    "            cfg_eval = compose(\n",
    "                config_name=\"eval_model_mumford\",\n",
    "                overrides=[\n",
    "                    f\"+eval={dataset_name.lower()}\",\n",
    "                    f\"+model.weights={model_weights_path}\",\n",
    "                    f\"++run_name={initial_routes_name}\",\n",
    "                    f\"++experiment.cost_function.kwargs.demand_time_weight={dt}\",\n",
    "                    f\"++experiment.cost_function.kwargs.route_time_weight={rt}\",\n",
    "                    f\"++experiment.cost_function.kwargs.median_connectivity_weight={ct}\"\n",
    "                ]\n",
    "            )\n",
    "        eval_metrics = main_eval(cfg_eval)\n",
    "\n",
    "        with initialize_config_dir(config_dir=str(cfg_dir), version_base=None):\n",
    "            cfg_bee = compose(\n",
    "                config_name=\"neural_bco_mumford\",\n",
    "                overrides=[\n",
    "                    f\"+eval={dataset_name.lower()}\",\n",
    "                    f\"+model.weights={model_weights_path}\",\n",
    "                    f\"++run_name={generated_routes_name}\",\n",
    "                    f\"++experiment.cost_function.kwargs.demand_time_weight={dt}\",\n",
    "                    f\"++experiment.cost_function.kwargs.route_time_weight={rt}\",\n",
    "                    f\"++experiment.cost_function.kwargs.median_connectivity_weight={ct}\",\n",
    "                    f\"init.path=output_routes/nn_construction_{initial_routes_name}_routes.pkl\",\n",
    "                ]\n",
    "            )\n",
    "        bee_metrics = main_bee(cfg_bee)\n",
    "        bee_metrics['median_connectivity'] /= 60\n",
    "\n",
    "        keys_order = ['ATT', 'RTT', 'median_connectivity', 'cost', '$d_{un}$', '$d_0$', '$d_1$', '$d_2$']\n",
    "        row = [dataset_name.lower(), dt, rt, ct] + [round(bee_metrics[k].item(), 4) for k in keys_order]\n",
    "\n",
    "        with open(results_file, mode='a', newline='') as f:\n",
    "            csv.writer(f).writerow(row)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[✗] Failed {experiment_name}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "401d55cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating mandl:   0%|          | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "/root/TNDP_learning/learning/utils.py:320: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /pytorch/aten/src/ATen/native/ReduceOps.cpp:1831.)\n",
      "  out_stats = (final_costs.mean(), final_costs.std(), metrics)\n",
      "Evaluating mandl:  14%|█▍        | 1/7 [00:01<00:11,  1.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ",6.000,0.332,10.954,244.000,84.393,13.166,2.441,0.000,0.000,0.000,720.000,1.621,0.000\n",
      "{'cost': tensor([0.3319]), 'ATT': tensor([10.9538]), 'RTT': tensor([244.]), '$d_0$': tensor([84.3931]), '$d_1$': tensor([13.1663]), '$d_2$': tensor([2.4406]), '$d_{un}$': tensor([0.]), '# disconnected node pairs': tensor([0.]), '# stops out of bounds': tensor([0.]), 'median_connectivity': tensor([720.]), 'average wall-clock duration': tensor([1.6207]), 'average # iterations': tensor([0.])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, -1.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ",6.000,0.747,13.493,148.000,59.216,36.609,4.110,0.064,0.000,0.000,868.000,-0.701,0.000\n",
      "{'cost': tensor([0.7475]), 'ATT': tensor([13.4926]), 'RTT': tensor([148.]), '$d_0$': tensor([59.2164]), '$d_1$': tensor([36.6089]), '$d_2$': tensor([4.1105]), '$d_{un}$': tensor([0.0642]), '# disconnected node pairs': tensor([0.]), '# stops out of bounds': tensor([0.]), 'median_connectivity': tensor([868.]), 'average wall-clock duration': tensor([-0.7006]), 'average # iterations': tensor([0.])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.60s/it]\n",
      "Evaluating mandl:  43%|████▎     | 3/7 [00:02<00:03,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ",6.000,0.362,11.101,240.000,79.833,19.075,1.092,0.000,0.000,0.000,716.000,1.597,0.000\n",
      "{'cost': tensor([0.3616]), 'ATT': tensor([11.1015]), 'RTT': tensor([240.]), '$d_0$': tensor([79.8330]), '$d_1$': tensor([19.0751]), '$d_2$': tensor([1.0918]), '$d_{un}$': tensor([0.]), '# disconnected node pairs': tensor([0.]), '# stops out of bounds': tensor([0.]), 'median_connectivity': tensor([716.]), 'average wall-clock duration': tensor([1.5975]), 'average # iterations': tensor([0.])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.61s/it]\n",
      "Evaluating mandl:  57%|█████▋    | 4/7 [00:04<00:03,  1.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ",6.000,0.585,13.248,152.000,59.409,39.435,1.156,0.000,0.000,0.000,816.000,1.600,0.000\n",
      "{'cost': tensor([0.5846]), 'ATT': tensor([13.2479]), 'RTT': tensor([152.]), '$d_0$': tensor([59.4091]), '$d_1$': tensor([39.4348]), '$d_2$': tensor([1.1561]), '$d_{un}$': tensor([0.]), '# disconnected node pairs': tensor([0.]), '# stops out of bounds': tensor([0.]), 'median_connectivity': tensor([816.]), 'average wall-clock duration': tensor([1.6001]), 'average # iterations': tensor([0.])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.61s/it]\n",
      "Evaluating mandl:  71%|███████▏  | 5/7 [00:06<00:02,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ",6.000,0.348,10.954,244.000,84.393,13.166,2.441,0.000,0.000,0.000,720.000,1.601,0.000\n",
      "{'cost': tensor([0.3478]), 'ATT': tensor([10.9538]), 'RTT': tensor([244.]), '$d_0$': tensor([84.3931]), '$d_1$': tensor([13.1663]), '$d_2$': tensor([2.4406]), '$d_{un}$': tensor([0.]), '# disconnected node pairs': tensor([0.]), '# stops out of bounds': tensor([0.]), 'median_connectivity': tensor([720.]), 'average wall-clock duration': tensor([1.6012]), 'average # iterations': tensor([0.])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.60s/it]\n",
      "Evaluating mandl:  86%|████████▌ | 6/7 [00:08<00:01,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ",6.000,0.590,13.248,152.000,59.409,39.435,1.156,0.000,0.000,0.000,816.000,1.597,0.000\n",
      "{'cost': tensor([0.5899]), 'ATT': tensor([13.2479]), 'RTT': tensor([152.]), '$d_0$': tensor([59.4091]), '$d_1$': tensor([39.4348]), '$d_2$': tensor([1.1561]), '$d_{un}$': tensor([0.]), '# disconnected node pairs': tensor([0.]), '# stops out of bounds': tensor([0.]), 'median_connectivity': tensor([816.]), 'average wall-clock duration': tensor([1.5967]), 'average # iterations': tensor([0.])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Evaluating mandl: 100%|██████████| 7/7 [00:09<00:00,  1.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ",6.000,0.524,12.087,164.000,69.043,28.003,2.954,0.000,0.000,0.000,780.000,1.620,0.000\n",
      "{'cost': tensor([0.5242]), 'ATT': tensor([12.0873]), 'RTT': tensor([164.]), '$d_0$': tensor([69.0430]), '$d_1$': tensor([28.0026]), '$d_2$': tensor([2.9544]), '$d_{un}$': tensor([0.]), '# disconnected node pairs': tensor([0.]), '# stops out of bounds': tensor([0.]), 'median_connectivity': tensor([780.]), 'average wall-clock duration': tensor([1.6195]), 'average # iterations': tensor([0.])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Эксперименты только с mandl\n",
    "import csv\n",
    "from pathlib import Path\n",
    "from hydra import initialize_config_dir, compose\n",
    "from learning.eval_route_generator import main as main_eval\n",
    "from tqdm import tqdm\n",
    "\n",
    "model_weights_path = \"../TNDP_learning/output/inductive_random_graphs_checkpoints/iter990.pt\"\n",
    "\n",
    "mandl_experiments = [\n",
    "    (\"mandl\", 1, 0, 0),\n",
    "    (\"mandl\", 0, 1, 0),\n",
    "    (\"mandl\", 0, 0, 1),\n",
    "    (\"mandl\", 0.5, 0.5, 0),\n",
    "    (\"mandl\", 0.5, 0, 0.5),\n",
    "    (\"mandl\", 0, 0.5, 0.5),\n",
    "    (\"mandl\", 0.33, 0.33, 0.33),\n",
    "]\n",
    "\n",
    "# CSV файл\n",
    "results_file = Path(\"eval_only_mandl.csv\")\n",
    "if not results_file.exists():\n",
    "    with open(results_file, mode='w', newline='') as f:\n",
    "        csv.writer(f).writerow([\n",
    "            \"dataset\", \"demand_time\", \"route_time\", \"connectivity\",\n",
    "            \"ATT\", \"RTT\", \"median_connectivity\", \"cost\", \"$d_{un}$\", \"$d_0$\", \"$d_1$\", \"$d_2$\"\n",
    "        ])\n",
    "\n",
    "# Запуск экспериментов только main_eval\n",
    "for dataset_name, dt, rt, ct in tqdm(mandl_experiments, desc=\"Evaluating mandl\"):\n",
    "    try:\n",
    "        run_name = f\"mandl_eval_pp_{dt}_op_{rt}_cp_{ct}\"\n",
    "\n",
    "        with initialize_config_dir(config_dir=str(cfg_dir), version_base=None):\n",
    "            cfg_eval = compose(\n",
    "                config_name=\"eval_model_mumford\",\n",
    "                overrides=[\n",
    "                    f\"+eval={dataset_name}\",\n",
    "                    f\"+model.weights={model_weights_path}\",\n",
    "                    f\"++run_name={run_name}\",\n",
    "                    f\"++experiment.cost_function.kwargs.demand_time_weight={dt}\",\n",
    "                    f\"++experiment.cost_function.kwargs.route_time_weight={rt}\",\n",
    "                    f\"++experiment.cost_function.kwargs.median_connectivity_weight={ct}\",\n",
    "                ]\n",
    "            )\n",
    "\n",
    "        metrics = main_eval(cfg_eval)\n",
    "        keys_order = ['ATT', 'RTT', 'median_connectivity', 'cost', '$d_{un}$', '$d_0$', '$d_1$', '$d_2$']\n",
    "        row = [dataset_name, dt, rt, ct] + [round(metrics[k].item(), 4) for k in keys_order]\n",
    "\n",
    "        with open(results_file, mode='a', newline='') as f:\n",
    "            csv.writer(f).writerow(row)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[✗] Failed eval for {run_name}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1236a1cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
